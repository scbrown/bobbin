# Plan: Eval Results Preservation + Matplotlib Charts

## Context

The eval framework has two problems: (1) result JSON files are gitignored so historical runs are lost, and (2) the mdbook charts are hand-rolled SVG rectangles that are extremely basic. An earlier run showed bobbin winning (+50pp precision, -39% duration) but a re-run overwrote those results with identical metrics. We need permanent storage of all runs and charts worth looking at.

## Overview

1. Commit all eval result JSONs to git, organized by run ID
2. Replace hand-rolled SVG with matplotlib (Dracula-themed)
3. Enhance mdbook pages: multi-metric charts, distributions, historical trends

## Beads

| Bead | Title | Depends on | Parallelizable with |
|------|-------|------------|---------------------|
| `bobbin-gpne` | Scaffolding — stubs, tests, structure | none | — |
| `bobbin-anvd` | Run-based result storage in CLI | gpne | bobbin-3uiy |
| `bobbin-3uiy` | Matplotlib chart module | gpne | bobbin-anvd |
| `bobbin-l5em` | Rewrite mdbook page generators | anvd + 3uiy | — |
| `bobbin-g9bf` | Update report.py and CSS | gpne + anvd | bobbin-3uiy |

---

## Phase 1: Result Storage Reorganization

### 1.1 New directory structure

```
eval/results/
  runs/
    20260210-143052-a1b2/          # YYYYMMDD-HHMMSS-4hex
      manifest.json                 # run metadata
      flask-001_no-bobbin_0.json
      flask-001_with-bobbin_0.json
      judge_results.json            # optional
    20260215-091230-c3d4/
      manifest.json
      ...
```

### 1.2 Changes

**`eval/.gitignore`** — Remove `results/*.json` and `results/*.md` exclusions. Keep Python ignores only.

**`eval/runner/cli.py`** — Add:
- `_generate_run_id()` → `YYYYMMDD-HHMMSS-XXXX` (4 random hex)
- Modify `_save_result()` to save into `results/runs/<run_id>/`
- Add `run_id` field to each result JSON
- Write `manifest.json` per run (run_id, started_at, completed_at, model, tasks, approaches, attempts)
- Wire run_id through `run_task` and `run_all` commands
- Update `judge` command to save into the run directory

**`eval/analysis/mdbook_pages.py`** — Update `_load_results()` to scan `results/runs/*/` with fallback to flat `results/*.json` (legacy compat, synthetic `"legacy"` run_id).

**`eval/analysis/report.py`** — Same `_load_results()` update.

### 1.3 Manifest format

```json
{
  "run_id": "20260210-143052-a1b2",
  "started_at": "2026-02-10T14:30:52Z",
  "completed_at": "2026-02-10T15:45:12Z",
  "model": "claude-sonnet-4-5-20250929",
  "attempts_per_approach": 3,
  "approaches": ["no-bobbin", "with-bobbin"],
  "tasks": ["flask-001", "flask-002"],
  "total_results": 12,
  "completed_results": 12
}
```

---

## Phase 2: Matplotlib Chart Module

### 2.1 Setup

**`eval/pyproject.toml`** — Add `matplotlib>=3.8` to dependencies.

**`eval/analysis/mpl_charts.py`** (new) — All chart generation:
- `apply_dracula_theme()` — sets rcParams for Dracula palette
- `fig_to_svg(fig)` — renders Figure to SVG string, strips XML declaration for inline use
- Uses `matplotlib.use("Agg")` for headless operation
- Sets `svg.fonttype: none` to avoid embedding fonts (keeps SVG small)

### 2.2 Chart functions

Each returns an SVG string via `fig_to_svg()`.

| Function | Purpose | Used on |
|----------|---------|---------|
| `grouped_bar_chart(groups, title)` | F1/precision/recall bars by task, grouped by approach | summary, per-project |
| `multi_metric_chart(stats_by_approach)` | Side-by-side precision/recall/F1 for each approach | summary |
| `box_plot_chart(data_by_approach, metric)` | Distribution across attempts (median, quartiles, outliers) | summary, per-task |
| `duration_chart(durations_by_approach)` | Horizontal bars with error bars for timing | summary, per-task |
| `trend_chart(runs_data, metric)` | Line chart of metric across historical runs | trends page |
| `heatmap_chart(runs_data, metric)` | Tasks (Y) x Runs (X), color = metric value | trends page |

### 2.3 SVG embedding approach

Charts saved as `.svg` files in `docs/book/src/eval/charts/` and referenced from markdown as `![title](./charts/filename.svg)`. Rationale: matplotlib SVGs are verbose (50-100KB); external files keep markdown clean. The `charts/` directory is generated by `publish`, not committed.

---

## Phase 3: Enhanced mdbook Pages

### 3.1 Updated `summary.md`

- Overall comparison table (same format, latest run)
- **Multi-metric bar chart**: precision + recall + F1 side by side
- **F1 by task**: grouped bars per task
- **Score distributions**: box plots when multiple attempts exist
- **Duration comparison**: horizontal bar chart
- **Quick trend**: last 5 runs line chart (links to full trends)
- Per-task results table

### 3.2 Updated `flask.md` / `ruff.md`

- Per-task box plots for score distributions
- Duration chart per task
- Files-touched comparison (existing, keep)
- Judge verdicts (existing, keep)

### 3.3 New `trends.md` — Historical Trends

- F1 trend line chart across all runs
- Test pass rate trend
- Duration trend
- Per-run comparison table
- Task heatmap (tasks x runs, color = F1)

### 3.4 `SUMMARY.md` update

Add under Evaluation section:
```markdown
- [Historical Trends](eval/trends.md)
```

### 3.5 CSS updates

`docs/book/custom/css/custom.css` — add `.eval-chart img` styling for chart containers.

---

## Phase 4: CLI Integration

**`eval/runner/cli.py` `publish` command** — Add options:
- `--run <run-id>` — publish a specific run (default: latest)
- `--all-runs` — include historical trends from all runs
- Generate `charts/` directory alongside markdown

---

## Files Modified

| File | Change |
|------|--------|
| `eval/.gitignore` | Remove JSON/MD exclusions |
| `eval/pyproject.toml` | Add matplotlib dep |
| `eval/runner/cli.py` | Run ID generation, save path, manifest, publish options |
| `eval/analysis/mdbook_pages.py` | Multi-run loading, new charts, trends page, updated generators |
| `eval/analysis/report.py` | Update `_load_results()` for new directory structure |
| `docs/book/src/SUMMARY.md` | Add trends page entry |
| `docs/book/custom/css/custom.css` | Chart image styling |

## Files Created

| File | Purpose |
|------|---------|
| `eval/analysis/mpl_charts.py` | Matplotlib chart generation (Dracula theme) |
| `eval/tests/test_mpl_charts.py` | Chart function tests |
| `eval/tests/test_run_storage.py` | Run storage tests |

## Files Deprecated

| File | Status |
|------|--------|
| `eval/analysis/svg_charts.py` | Replaced by mpl_charts.py; keep temporarily, add deprecation note |

---

## Implementation Order

1. **`bobbin-gpne`** — Scaffolding: gitignore, stubs, test stubs, pyproject, SUMMARY.md
2. **`bobbin-anvd`** + **`bobbin-3uiy`** — (parallel) Run storage + matplotlib charts
3. **`bobbin-g9bf`** — Report.py and CSS updates
4. **`bobbin-l5em`** — Rewrite mdbook page generators (depends on 2)

## Verification

1. Create mock result data in `eval/results/runs/` with 2+ runs
2. Run `bobbin-eval publish --all-runs` → verify markdown + charts generated
3. Run `just docs build` (or `mdbook build docs/book`) → verify pages render
4. Inspect generated SVGs have Dracula colors and correct data
5. Run `python -m pytest eval/tests/` → all tests pass
